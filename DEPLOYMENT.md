# Deployment Guide — Render (Free Tier)

This guide walks through deploying the Enterprise AI Gateway to Render's free tier ($0/month).

## Prerequisites

- GitHub account with your code pushed
- Render account (sign up at [render.com](https://render.com))
- API keys for LLM providers (OpenAI, Anthropic, Gemini)

---

## Step 1: Push to GitHub

```bash
git add .
git commit -m "Add Render deployment configuration"
git push origin main
```

---

## Step 2: Connect to Render

1. Go to [Render Dashboard](https://dashboard.render.com)
2. Click **"New"** → **"Blueprint"**
3. Click **"Connect GitHub"** and authorize Render
4. Select your repository: `enterprise-ai-gateway`
5. Render auto-detects `render.yaml` and shows:
   - ✅ Web Service: `enterprise-ai-gateway`
   - ✅ PostgreSQL: `gateway-db` (1GB free)
   - ✅ Redis: `gateway-redis` (25MB free, Valkey)

6. Click **"Apply"** to create all services

---

## Step 3: Set Environment Variables

After services are created, add your API keys:

1. Go to **Dashboard** → **enterprise-ai-gateway** (web service)
2. Click **"Environment"** in the sidebar
3. Add the following secrets:

```
OPENAI_API_KEY=sk-proj-...
ANTHROPIC_API_KEY=sk-ant-...
GEMINI_API_KEY=AIza...
```

**Note:** `DATABASE_URL`, `REDIS_URL`, and `ADMIN_API_KEY` are auto-generated by Render.

4. Click **"Save Changes"** → triggers redeploy

---

## Step 4: Wait for Deployment

- First deployment: **5-10 minutes**
- Render builds Docker image from `Dockerfile`
- Initializes PostgreSQL schema automatically
- Starts web service

Watch deployment logs in the Render dashboard.

---

## Step 5: Verify Deployment

Once deployed, test the live gateway:

### Health Check
```bash
curl https://enterprise-ai-gateway.onrender.com/health
```

Expected response:
```json
{
  "status": "healthy",
  "providers": {
    "anthropic": "available",
    "openai": "available",
    "gemini": "available",
    "ollama": "unavailable"
  }
}
```

### Readiness Check (DB + Redis)
```bash
curl https://enterprise-ai-gateway.onrender.com/ready
```

Expected response:
```json
{
  "status": "ready",
  "checks": {
    "database": true,
    "redis": true
  }
}
```

---

## Step 6: Create Your First API Key

```bash
# Get the auto-generated ADMIN_API_KEY from Render dashboard
# Then create a tenant API key:

curl -X POST https://enterprise-ai-gateway.onrender.com/admin/keys \
  -H "X-API-Key: YOUR_ADMIN_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "tenant_id": "my-app",
    "rate_limit_per_minute": 100
  }'
```

Response:
```json
{
  "tenant_id": "my-app",
  "api_key": "lgw_...",
  "warning": "Schlüssel wird nicht erneut angezeigt. Sofort sicher speichern!"
}
```

**IMPORTANT:** Save the `api_key` — it's shown only once!

---

## Step 7: Test LLM Routing

```bash
curl -X POST https://enterprise-ai-gateway.onrender.com/v1/chat/completions \
  -H "X-API-Key: lgw_YOUR_KEY_HERE" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What is 2+2?"}
    ],
    "model": "auto",
    "eu_residency_required": false
  }'
```

The gateway will:
- Route to cheapest provider (likely Gemini Flash)
- Detect PII (if any German data)
- Log to audit trail
- Return OpenAI-compatible response

---

## Auto-Deploy on Git Push

After initial setup, every `git push origin main` triggers automatic redeployment.

```bash
# Make changes
git add .
git commit -m "Update routing logic"
git push origin main

# Render automatically:
# 1. Pulls latest code
# 2. Rebuilds Docker image
# 3. Runs health checks
# 4. Deploys if passing
```

---

## Free Tier Limits

| Resource | Limit | Notes |
|----------|-------|-------|
| Web Service | 750 hours/month | Spins down after 15 min inactivity |
| PostgreSQL | 1GB storage | 97 connections max |
| Redis | 25MB memory | ~10K rate limit entries |
| Cold Start | ~30 seconds | First request after spin-down |

**Upgrade path:** Render paid tiers start at $7/month for always-on web service.

---

## Monitoring

### Render Dashboard
- View logs: **Dashboard** → **enterprise-ai-gateway** → **Logs**
- Metrics: CPU, memory, request count
- Deployment history

### Custom Endpoints
- `/health` — Provider availability
- `/ready` — DB + Redis connectivity
- `/admin/keys` — API key management

---

## Troubleshooting

### Cold Start Delays
**Symptom:** First request takes 30+ seconds
**Solution:** Upgrade to paid tier ($7/mo) for always-on service

### Database Connection Errors
**Symptom:** `FATAL: remaining connection slots are reserved`
**Solution:** Free tier has 97 connections max. Check connection pooling.

### Redis Memory Full
**Symptom:** Rate limiter stops working
**Solution:** 25MB limit reached. Consider upgrading or reducing rate limit window.

### API Keys Not Working
**Symptom:** `401 Unauthorized`
**Check:**
1. API key format: `lgw_...` (not raw UUID)
2. Header: `X-API-Key: lgw_...` or `Authorization: Bearer lgw_...`
3. Key is active in database

---

## Cost Breakdown

**Free Tier (Current):**
- Web service: $0/month (750 hours)
- PostgreSQL: $0/month (forever free, 1GB)
- Redis: $0/month (forever free, 25MB)
- **Total: $0/month** ✅

**Paid Upgrade Options:**
- Starter ($7/mo): Always-on web service, no cold starts
- Standard ($25/mo): 4GB PostgreSQL, 256MB Redis, autoscaling
- Pro ($85/mo): 16GB PostgreSQL, 1GB Redis, priority support

---

## Next Steps

1. ✅ **Deployed to production** — Gateway live at `*.onrender.com`
2. **Add monitoring:** Prometheus + Grafana dashboard (Session 5)
3. **CI/CD pipeline:** GitHub Actions for automated testing
4. **MCP server:** Expose gateway via Model Context Protocol

---

## Support

- **Render Status:** [status.render.com](https://status.render.com)
- **Render Docs:** [render.com/docs](https://render.com/docs)
- **Gateway Issues:** [GitHub Issues](https://github.com/YOUR_USERNAME/enterprise-ai-gateway/issues)
